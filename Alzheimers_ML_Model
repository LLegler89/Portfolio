
#Importing required modules

!pip install tensorflow opencv-python

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

# Define image size and directory
img_size = (128, 128)
data_dir = 'Input data directory path'

# Function to load and preprocess images
def load_and_preprocess_data(data_dir):
    images = []
    labels = []

    for label in os.listdir(data_dir):
        label_path = os.path.join(data_dir, label)
        
        for filename in os.listdir(label_path):
            img_path = os.path.join(label_path, filename)
            img = cv2.imread(img_path)
            img = cv2.resize(img, img_size)
            img = img / 255.0  # Normalize pixel values
            images.append(img)
            labels.append(label)

    return np.array(images), np.array(labels)

# Load and preprocess data
images, labels = load_and_preprocess_data(data_dir)

# Encode labels
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Define the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(4, activation='softmax')  # Adjust the number of units based on your classes
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Evaluate the model
y_pred = np.argmax(model.predict(X_test), axis=-1)
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))


# Load and preprocess a test image 
def load_and_preprocess_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (128, 128))
    img = img / 255.0  # Normalize pixel values
    return np.expand_dims(img, axis=0)  # Add a batch dimension


new_img_path = 'Insert image path'
new_img = load_and_preprocess_image(new_img_path)

# Make a prediction
prediction = model.predict(new_img)

# Decode the prediction
predicted_class = np.argmax(prediction)
predicted_label = label_encoder.classes_[predicted_class]

print(f'The model predicts: {predicted_label}')


# Visualize

import matplotlib.pyplot as plt

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Create a confusion matrix

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Feature map visualization 

from tensorflow.keras.models import Model

# First we will choose a layer to visualize
layer_to_visualize = model.layers[0]

# Creating a model that outputs the layer's output
activation_model = Model(inputs=model.input, outputs=layer_to_visualize.output)

# Get the activation of the layer for a sample image
activation = activation_model.predict(new_img)

# Visualize the feature maps
plt.imshow(activation[0, :, :, 0], cmap='viridis')
plt.title('Feature Map')
plt.show()
